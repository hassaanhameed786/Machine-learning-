{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPozeurlCw2nwhMqPziHxu6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hassaanhameed786/Machine-learning-/blob/main/mammals_image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Importing Essential Packages**\n",
        "The article starts with importing necessary Python packages:\n",
        "\n",
        "pandas, numpy: For data handling and numerical operations.\n",
        "seaborn, matplotlib.pyplot, plotly: For visualizing data and results.\n",
        "os: For file and directory operations.\n",
        "cv2 (OpenCV): For reading and manipulating images.\n",
        "tensorflow, torch: For building and training deep learning models.\n",
        "Understanding and using these libraries will be crucial as each serves a specific purpose in the process of data handling, model building, and visualization.\n",
        "\n",
        "# **2. Loading Images**\n",
        "Using cv2 to load images from a directory structure is a common approach. This involves iterating through each subdirectory and file, loading each image, and possibly storing them in a list or an array for further processing. This step is crucial for building your dataset.\n",
        "\n",
        "# **3. Counting Subdirectories and Images**\n",
        "Understanding the structure of your dataset is vital. Counting directories and images helps you know how many categories (classes) you have and how many images are in each category, which is essential for understanding the balance of your dataset.\n",
        "\n",
        "# **4. Analyzing Image Properties**\n",
        "Investigating image properties such as size, resolution, and color distribution can provide insights into the variability within your dataset and any preprocessing steps you might need to standardize the images.\n",
        "\n",
        "# **5. Visualizing Data Distribution**\n",
        "Creating visualizations like bar charts and scatter plots helps in understanding the distribution of your data across different classes and the variations in image properties. This step is crucial for identifying imbalances or outliers that might affect model training.\n",
        "\n",
        "# **6. Training a Basic CNN Model**\n",
        "Here's where you dive into model building. A basic CNN usually consists of convolutional layers, pooling layers, and fully connected layers. The article describes the process of defining the architecture, compiling the model, and then training it on your image data.\n",
        "\n",
        "# **7. Training a Transfer Learning Model**\n",
        "Transfer learning involves using a pre-trained model and adapting it to your specific task. This approach is particularly useful when you have a small dataset or want to save time and computational resources. The article mentions adapting MobileNetV2, but there are many other models like ResNet, VGG, and Inception that you can explore.\n",
        "\n",
        "# **8. Evaluating the Model**\n",
        "Once your model is trained, it's crucial to evaluate its performance using metrics like accuracy, precision, recall, and F1-score, and by plotting accuracy and loss curves. This helps in understanding how well the model is performing and whether it's overfitting or underfitting.\n",
        "\n",
        "# **9. Making Predictions**\n",
        "Finally, the article describes how to use your trained model to make predictions on new images. This involves preprocessing the image to fit the input requirements of your model, then feeding it through the model to get a prediction."
      ],
      "metadata": {
        "id": "pZTBe2U_NSXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Python Package\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import os\n",
        "import zipfile\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from plotly.subplots import make_subplots\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from PIL import Image\n",
        "import plotly.offline as pyo\n",
        "from IPython.display import display\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "azw2zvIMYYbc"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWdRU3pEVy-P",
        "outputId": "52227ee0-bb42-48c8-cc90-0b8ef199ba72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mounting the drive for the dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ovDyYsRDNNO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = '/content/drive/MyDrive/Datasets/archive (2).zip'"
      ],
      "metadata": {
        "id": "zsBrw1gSoYsJ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Locate the Zip File"
      ],
      "metadata": {
        "id": "0jRmugViqPeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the target directory where you want to extract the content\n",
        "extract_to = '/content/mammals_dataset'\n",
        "\n",
        "# Create the directory if it does not exist\n",
        "if not os.path.exists(extract_to):\n",
        "    os.makedirs(extract_to)\n",
        "\n",
        "# Define the path to the zip file\n",
        "zip_path = '/content/drive/MyDrive/Datasets/archive (2).zip'\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)"
      ],
      "metadata": {
        "id": "b_YP0FBjWArU"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Space Efficiency:\n",
        "\n",
        "Keeping your data zipped until needed can save space in your Google Drive, which has limited free storage.\n",
        "## Time Efficiency:\n",
        "\n",
        " Uploading one large zip file can be faster and more reliable than uploading many small files, especially for a large dataset.\n",
        "##Extraction Location:\n",
        " Make sure you have enough space in your Colab environment to extract all files, as it offers limited and temporary storage.\n",
        "italicised text"
      ],
      "metadata": {
        "id": "IILqWzjlpea1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(extract_to)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knpD5egxqFDr",
        "outputId": "471fb5aa-284f-47bd-c31a-b1ac90f408be"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mammals']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mammals = os.listdir(extract_to)\n",
        "\n",
        "# Loop through each mammal's folder and load images\n",
        "for mammal in mammals:\n",
        "    mammal_folder = os.path.join(extract_to, mammal)\n",
        "    images = os.listdir(mammal_folder)\n",
        "    for image in images:\n",
        "        image_path = os.path.join(mammal_folder, image)\n",
        "        if os.path.isfile(image_path):\n",
        "            img = Image.open(image_path)  # Or use any other library for image loading\n",
        "            # Now you can use img in your processing..."
      ],
      "metadata": {
        "id": "UqxRDE2Rp6jm"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path"
      ],
      "metadata": {
        "id": "o25r8PfsYiKl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "95000f2a-1992-47e0-9a2d-49e4ba3a7353"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/mammals_dataset/mammals/wildebeest'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yoi2VgIYqa5o"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pbznEHRNqa85"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KgNrCwDRqa-y"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uPnmRsHqqbAn"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k0UeJ-FjqbCS"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WD-69Dc3qbI_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GSg16Tu1qbLD"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D8zNFyt0qbNA"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HOhMo22iqbPN"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZemFnM5kqbRb"
      },
      "execution_count": 33,
      "outputs": []
    }
  ]
}